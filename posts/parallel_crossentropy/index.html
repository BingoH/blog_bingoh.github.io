<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> About Cross Entropy </title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="About Cross Entropy" />
<meta property="og:description" content="Cross entropy loss(交互熵)是多分类问题中最常用的损失函数。它可以由最大似然得到，也可以从KL散度(Kullback-Leibler divergence)导出。本文记录cross entropy loss的推导和梯度计算，以及在实现时遇到的问题。
推导 最大似然 对于样本点$(x_i, y_i)$,我们最大化其在目标类别上的概率$P(y_i|x_i, \theta)$,$\theta$表示模型参数。若样本$x_i$提取特征$f_i \in \mathbb{R}^d$，通常利用softmax分类器得到概率分布$P(y=j|f_i) = \frac{\exp(w_j^Tf_i)}{\sum_{k=1}^C \exp(w_k^T f_i)}$，其中$w_k,k=1, \ldots, C$为分类器参数。因此利用最大似然法的到目标函数 $$ \max \mathcal{L} = \max \Pi_{i=1}^N P(y_i|f_i) = \max \Pi_{i=1}^N \frac{\exp(w_i^Tf_i)}{\sum_{k=1}^C \exp(w_k^T f_i)}, $$其等价于 $$ \max \log \mathcal{L} = \max \sum_{i=1}^N \log P(y_i|f_i) $$ $z^i = [w_1^Tf_i, \ldots, w_C^T f_i]$称为logits。
KL散度 利用KL散度衡量概率分布的距离：预测分布$P(y=j|f_i)= \frac{\exp(z^i_j)}{\sum_k \exp(z^i_k)} $以及样本真实分布$Q(y=j|f_i)= \begin{cases} 1, j=y_i \ 0, \text{otherwise} \end{cases}$，得到 $$ \min \text{KL}(P, Q) = \sum_{j=1}^C Q(y=j|f_i) \log \frac{Q(y=j|f_i)}{P(y=j|f_i)} = -\log P(y_i|f_i) $$" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.bingoai.tk/posts/parallel_crossentropy/" />
<meta property="article:published_time" content="2020-09-02T19:19:30+08:00" />
<meta property="article:modified_time" content="2020-09-02T19:19:30+08:00" />

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="About Cross Entropy"/>
<meta name="twitter:description" content="Cross entropy loss(交互熵)是多分类问题中最常用的损失函数。它可以由最大似然得到，也可以从KL散度(Kullback-Leibler divergence)导出。本文记录cross entropy loss的推导和梯度计算，以及在实现时遇到的问题。
推导 最大似然 对于样本点$(x_i, y_i)$,我们最大化其在目标类别上的概率$P(y_i|x_i, \theta)$,$\theta$表示模型参数。若样本$x_i$提取特征$f_i \in \mathbb{R}^d$，通常利用softmax分类器得到概率分布$P(y=j|f_i) = \frac{\exp(w_j^Tf_i)}{\sum_{k=1}^C \exp(w_k^T f_i)}$，其中$w_k,k=1, \ldots, C$为分类器参数。因此利用最大似然法的到目标函数 $$ \max \mathcal{L} = \max \Pi_{i=1}^N P(y_i|f_i) = \max \Pi_{i=1}^N \frac{\exp(w_i^Tf_i)}{\sum_{k=1}^C \exp(w_k^T f_i)}, $$其等价于 $$ \max \log \mathcal{L} = \max \sum_{i=1}^N \log P(y_i|f_i) $$ $z^i = [w_1^Tf_i, \ldots, w_C^T f_i]$称为logits。
KL散度 利用KL散度衡量概率分布的距离：预测分布$P(y=j|f_i)= \frac{\exp(z^i_j)}{\sum_k \exp(z^i_k)} $以及样本真实分布$Q(y=j|f_i)= \begin{cases} 1, j=y_i \ 0, \text{otherwise} \end{cases}$，得到 $$ \min \text{KL}(P, Q) = \sum_{j=1}^C Q(y=j|f_i) \log \frac{Q(y=j|f_i)}{P(y=j|f_i)} = -\log P(y_i|f_i) $$"/>

  
  
    
  
  
  <link rel="stylesheet" href="https://blog.bingoai.tk/css/style-light.css">
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://blog.bingoai.tk/images/favicon.ico" />

  
  
  
</head>
<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/posts">Posts</a></li>
         
        <li><a href="/tags">Tags</a></li>
         
        <li><a href="/about">About</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" https://blog.bingoai.tk/posts/first-post/">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&text=About%20Cross%20Entropy">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&is_video=false&description=About%20Cross%20Entropy">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=About%20Cross%20Entropy&body=Check out this article: https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.stumbleupon.com/submit?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-stumbleupon " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://digg.com/submit?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-digg " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&name=About%20Cross%20Entropy&description=Cross%20entropy%20loss%28%e4%ba%a4%e4%ba%92%e7%86%b5%29%e6%98%af%e5%a4%9a%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%ad%e6%9c%80%e5%b8%b8%e7%94%a8%e7%9a%84%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e3%80%82%e5%ae%83%e5%8f%af%e4%bb%a5%e7%94%b1%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%e5%be%97%e5%88%b0%ef%bc%8c%e4%b9%9f%e5%8f%af%e4%bb%a5%e4%bb%8eKL%e6%95%a3%e5%ba%a6%28Kullback-Leibler%20divergence%29%e5%af%bc%e5%87%ba%e3%80%82%e6%9c%ac%e6%96%87%e8%ae%b0%e5%bd%95cross%20entropy%20loss%e7%9a%84%e6%8e%a8%e5%af%bc%e5%92%8c%e6%a2%af%e5%ba%a6%e8%ae%a1%e7%ae%97%ef%bc%8c%e4%bb%a5%e5%8f%8a%e5%9c%a8%e5%ae%9e%e7%8e%b0%e6%97%b6%e9%81%87%e5%88%b0%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%0a%e6%8e%a8%e5%af%bc%20%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%20%e5%af%b9%e4%ba%8e%e6%a0%b7%e6%9c%ac%e7%82%b9%24%28x_i%2c%20y_i%29%24%2c%e6%88%91%e4%bb%ac%e6%9c%80%e5%a4%a7%e5%8c%96%e5%85%b6%e5%9c%a8%e7%9b%ae%e6%a0%87%e7%b1%bb%e5%88%ab%e4%b8%8a%e7%9a%84%e6%a6%82%e7%8e%87%24P%28y_i%7cx_i%2c%20%5ctheta%29%24%2c%24%5ctheta%24%e8%a1%a8%e7%a4%ba%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e3%80%82%e8%8b%a5%e6%a0%b7%e6%9c%ac%24x_i%24%e6%8f%90%e5%8f%96%e7%89%b9%e5%be%81%24f_i%20%5cin%20%5cmathbb%7bR%7d%5ed%24%ef%bc%8c%e9%80%9a%e5%b8%b8%e5%88%a9%e7%94%a8softmax%e5%88%86%e7%b1%bb%e5%99%a8%e5%be%97%e5%88%b0%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%24P%28y%3dj%7cf_i%29%20%3d%20%5cfrac%7b%5cexp%28w_j%5eTf_i%29%7d%7b%5csum_%7bk%3d1%7d%5eC%20%5cexp%28w_k%5eT%20f_i%29%7d%24%ef%bc%8c%e5%85%b6%e4%b8%ad%24w_k%2ck%3d1%2c%20%5cldots%2c%20C%24%e4%b8%ba%e5%88%86%e7%b1%bb%e5%99%a8%e5%8f%82%e6%95%b0%e3%80%82%e5%9b%a0%e6%ad%a4%e5%88%a9%e7%94%a8%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%e6%b3%95%e7%9a%84%e5%88%b0%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0%20%24%24%20%5cmax%20%5cmathcal%7bL%7d%20%3d%20%5cmax%20%5cPi_%7bi%3d1%7d%5eN%20P%28y_i%7cf_i%29%20%3d%20%5cmax%20%5cPi_%7bi%3d1%7d%5eN%20%5cfrac%7b%5cexp%28w_i%5eTf_i%29%7d%7b%5csum_%7bk%3d1%7d%5eC%20%5cexp%28w_k%5eT%20f_i%29%7d%2c%20%24%24%e5%85%b6%e7%ad%89%e4%bb%b7%e4%ba%8e%20%24%24%20%5cmax%20%5clog%20%5cmathcal%7bL%7d%20%3d%20%5cmax%20%5csum_%7bi%3d1%7d%5eN%20%5clog%20P%28y_i%7cf_i%29%20%24%24%20%24z%5ei%20%3d%20%5bw_1%5eTf_i%2c%20%5cldots%2c%20w_C%5eT%20f_i%5d%24%e7%a7%b0%e4%b8%balogits%e3%80%82%0aKL%e6%95%a3%e5%ba%a6%20%e5%88%a9%e7%94%a8KL%e6%95%a3%e5%ba%a6%e8%a1%a1%e9%87%8f%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%e7%9a%84%e8%b7%9d%e7%a6%bb%ef%bc%9a%e9%a2%84%e6%b5%8b%e5%88%86%e5%b8%83%24P%28y%3dj%7cf_i%29%3d%20%5cfrac%7b%5cexp%28z%5ei_j%29%7d%7b%5csum_k%20%5cexp%28z%5ei_k%29%7d%20%24%e4%bb%a5%e5%8f%8a%e6%a0%b7%e6%9c%ac%e7%9c%9f%e5%ae%9e%e5%88%86%e5%b8%83%24Q%28y%3dj%7cf_i%29%3d%20%5cbegin%7bcases%7d%201%2c%20j%3dy_i%20%5c%200%2c%20%5ctext%7botherwise%7d%20%5cend%7bcases%7d%24%ef%bc%8c%e5%be%97%e5%88%b0%20%24%24%20%5cmin%20%5ctext%7bKL%7d%28P%2c%20Q%29%20%3d%20%5csum_%7bj%3d1%7d%5eC%20Q%28y%3dj%7cf_i%29%20%5clog%20%5cfrac%7bQ%28y%3dj%7cf_i%29%7d%7bP%28y%3dj%7cf_i%29%7d%20%3d%20-%5clog%20P%28y_i%7cf_i%29%20%24%24">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&t=About%20Cross%20Entropy">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    <div id="toc">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#推导">推导</a>
      <ul>
        <li><a href="#最大似然">最大似然</a></li>
        <li><a href="#kl散度">KL散度</a></li>
        <li><a href="#梯度计算">梯度计算</a></li>
      </ul>
    </li>
    <li><a href="#计算cross-entropy">计算cross entropy</a>
      <ul>
        <li><a href="#数值稳定算法">数值稳定算法</a></li>
        <li><a href="#并行版本">并行版本</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        About Cross Entropy
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          <time datetime="2020-09-02 19:19:30 &#43;0800 &#43;0800" itemprop="datePublished">2020-09-02</time>
          
        </div>
        
        
      </div>
    </header>

  
    <div class="content" itemprop="articleBody">
      <p>Cross entropy loss(交互熵)是多分类问题中最常用的损失函数。它可以由最大似然得到，也可以从KL散度(Kullback-Leibler divergence)导出。本文记录cross entropy loss的推导和梯度计算，以及在实现时遇到的问题。</p>
<h2 id="推导">推导</h2>
<h3 id="最大似然">最大似然</h3>
<p>对于样本点$(x_i, y_i)$,我们最大化其在目标类别上的概率$P(y_i|x_i, \theta)$,$\theta$表示模型参数。若样本$x_i$提取特征$f_i \in \mathbb{R}^d$，通常利用softmax分类器得到概率分布$P(y=j|f_i) = \frac{\exp(w_j^Tf_i)}{\sum_{k=1}^C \exp(w_k^T f_i)}$，其中$w_k,k=1, \ldots, C$为分类器参数。因此利用最大似然法的到目标函数
$$
\max \mathcal{L} = \max \Pi_{i=1}^N P(y_i|f_i) = \max \Pi_{i=1}^N \frac{\exp(w_i^Tf_i)}{\sum_{k=1}^C \exp(w_k^T f_i)},
$$其等价于
$$
\max \log \mathcal{L} = \max \sum_{i=1}^N \log P(y_i|f_i)
$$
$z^i = [w_1^Tf_i, \ldots, w_C^T f_i]$称为logits。</p>
<h3 id="kl散度">KL散度</h3>
<p>利用KL散度衡量概率分布的距离：预测分布$P(y=j|f_i)= \frac{\exp(z^i_j)}{\sum_k \exp(z^i_k)} $以及样本真实分布$Q(y=j|f_i)= \begin{cases} 1, j=y_i \ 0, \text{otherwise} \end{cases}$，得到
$$
\min \text{KL}(P, Q) = \sum_{j=1}^C Q(y=j|f_i) \log \frac{Q(y=j|f_i)}{P(y=j|f_i)} = -\log P(y_i|f_i)
$$</p>
<h3 id="梯度计算">梯度计算</h3>
<p>softmax分类器以及cross entropy loss得以广泛使用的原因之一为其梯度计算的方便。对于logits$z^i$和损失函数$\mathcal{L} = -\frac{1}{N}\sum_{i=1}^N \log \frac{\exp(z^i_{y_i})}{\sum_k \exp(z^i_k)}$可以得到
$$
\frac{\partial{\mathcal{L}}}{\partial{z^i_j}} = \frac{1}{N} [P(y_i|f_i)- \delta_{j, y_i}]
$$</p>
<h2 id="计算cross-entropy">计算cross entropy</h2>
<h3 id="数值稳定算法">数值稳定算法</h3>
<p>因指数和对数函数的性质，在实际计算中并不直接根据定义式子计算。例如如果logits有分量数值过大，则$\exp$容易overflow，或者某个分量数值过小，则$-\log$也可能趋向$inf$。即采用如下等价形式
$$
\mathcal{L_i} =  - \log \frac{\exp(z^i_{y_i})}{\sum_k \exp(z^i_k)} = -\log \frac{\exp(z^i_{y_i}-m)}{\sum_k \exp(z^i_k-m)} = - (z^i_{y_i} -m ) + \log \sum_k \exp(z^i_k-m)
$$</p>
<h3 id="并行版本">并行版本</h3>
<p>当分类类别数量$C$取极大值时，参数$w_i$以及logits将占用大量存储空间，对于深度CNN模型可能会导致GPU显存不够。此时可以将logits划分到多个GPU上实现cross entropy loss计算。</p>

    </div>
  </article>

  
  





  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/posts">Posts</a></li>
         
          <li><a href="/tags">Tags</a></li>
         
          <li><a href="/about">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#推导">推导</a>
      <ul>
        <li><a href="#最大似然">最大似然</a></li>
        <li><a href="#kl散度">KL散度</a></li>
        <li><a href="#梯度计算">梯度计算</a></li>
      </ul>
    </li>
    <li><a href="#计算cross-entropy">计算cross entropy</a>
      <ul>
        <li><a href="#数值稳定算法">数值稳定算法</a></li>
        <li><a href="#并行版本">并行版本</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&text=About%20Cross%20Entropy">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&is_video=false&description=About%20Cross%20Entropy">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=About%20Cross%20Entropy&body=Check out this article: https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.stumbleupon.com/submit?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://digg.com/submit?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&title=About%20Cross%20Entropy">
      <i class="fab fa-digg fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&name=About%20Cross%20Entropy&description=Cross%20entropy%20loss%28%e4%ba%a4%e4%ba%92%e7%86%b5%29%e6%98%af%e5%a4%9a%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%ad%e6%9c%80%e5%b8%b8%e7%94%a8%e7%9a%84%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e3%80%82%e5%ae%83%e5%8f%af%e4%bb%a5%e7%94%b1%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%e5%be%97%e5%88%b0%ef%bc%8c%e4%b9%9f%e5%8f%af%e4%bb%a5%e4%bb%8eKL%e6%95%a3%e5%ba%a6%28Kullback-Leibler%20divergence%29%e5%af%bc%e5%87%ba%e3%80%82%e6%9c%ac%e6%96%87%e8%ae%b0%e5%bd%95cross%20entropy%20loss%e7%9a%84%e6%8e%a8%e5%af%bc%e5%92%8c%e6%a2%af%e5%ba%a6%e8%ae%a1%e7%ae%97%ef%bc%8c%e4%bb%a5%e5%8f%8a%e5%9c%a8%e5%ae%9e%e7%8e%b0%e6%97%b6%e9%81%87%e5%88%b0%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%0a%e6%8e%a8%e5%af%bc%20%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%20%e5%af%b9%e4%ba%8e%e6%a0%b7%e6%9c%ac%e7%82%b9%24%28x_i%2c%20y_i%29%24%2c%e6%88%91%e4%bb%ac%e6%9c%80%e5%a4%a7%e5%8c%96%e5%85%b6%e5%9c%a8%e7%9b%ae%e6%a0%87%e7%b1%bb%e5%88%ab%e4%b8%8a%e7%9a%84%e6%a6%82%e7%8e%87%24P%28y_i%7cx_i%2c%20%5ctheta%29%24%2c%24%5ctheta%24%e8%a1%a8%e7%a4%ba%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e3%80%82%e8%8b%a5%e6%a0%b7%e6%9c%ac%24x_i%24%e6%8f%90%e5%8f%96%e7%89%b9%e5%be%81%24f_i%20%5cin%20%5cmathbb%7bR%7d%5ed%24%ef%bc%8c%e9%80%9a%e5%b8%b8%e5%88%a9%e7%94%a8softmax%e5%88%86%e7%b1%bb%e5%99%a8%e5%be%97%e5%88%b0%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%24P%28y%3dj%7cf_i%29%20%3d%20%5cfrac%7b%5cexp%28w_j%5eTf_i%29%7d%7b%5csum_%7bk%3d1%7d%5eC%20%5cexp%28w_k%5eT%20f_i%29%7d%24%ef%bc%8c%e5%85%b6%e4%b8%ad%24w_k%2ck%3d1%2c%20%5cldots%2c%20C%24%e4%b8%ba%e5%88%86%e7%b1%bb%e5%99%a8%e5%8f%82%e6%95%b0%e3%80%82%e5%9b%a0%e6%ad%a4%e5%88%a9%e7%94%a8%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%e6%b3%95%e7%9a%84%e5%88%b0%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0%20%24%24%20%5cmax%20%5cmathcal%7bL%7d%20%3d%20%5cmax%20%5cPi_%7bi%3d1%7d%5eN%20P%28y_i%7cf_i%29%20%3d%20%5cmax%20%5cPi_%7bi%3d1%7d%5eN%20%5cfrac%7b%5cexp%28w_i%5eTf_i%29%7d%7b%5csum_%7bk%3d1%7d%5eC%20%5cexp%28w_k%5eT%20f_i%29%7d%2c%20%24%24%e5%85%b6%e7%ad%89%e4%bb%b7%e4%ba%8e%20%24%24%20%5cmax%20%5clog%20%5cmathcal%7bL%7d%20%3d%20%5cmax%20%5csum_%7bi%3d1%7d%5eN%20%5clog%20P%28y_i%7cf_i%29%20%24%24%20%24z%5ei%20%3d%20%5bw_1%5eTf_i%2c%20%5cldots%2c%20w_C%5eT%20f_i%5d%24%e7%a7%b0%e4%b8%balogits%e3%80%82%0aKL%e6%95%a3%e5%ba%a6%20%e5%88%a9%e7%94%a8KL%e6%95%a3%e5%ba%a6%e8%a1%a1%e9%87%8f%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%e7%9a%84%e8%b7%9d%e7%a6%bb%ef%bc%9a%e9%a2%84%e6%b5%8b%e5%88%86%e5%b8%83%24P%28y%3dj%7cf_i%29%3d%20%5cfrac%7b%5cexp%28z%5ei_j%29%7d%7b%5csum_k%20%5cexp%28z%5ei_k%29%7d%20%24%e4%bb%a5%e5%8f%8a%e6%a0%b7%e6%9c%ac%e7%9c%9f%e5%ae%9e%e5%88%86%e5%b8%83%24Q%28y%3dj%7cf_i%29%3d%20%5cbegin%7bcases%7d%201%2c%20j%3dy_i%20%5c%200%2c%20%5ctext%7botherwise%7d%20%5cend%7bcases%7d%24%ef%bc%8c%e5%be%97%e5%88%b0%20%24%24%20%5cmin%20%5ctext%7bKL%7d%28P%2c%20Q%29%20%3d%20%5csum_%7bj%3d1%7d%5eC%20Q%28y%3dj%7cf_i%29%20%5clog%20%5cfrac%7bQ%28y%3dj%7cf_i%29%7d%7bP%28y%3dj%7cf_i%29%7d%20%3d%20-%5clog%20P%28y_i%7cf_i%29%20%24%24">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fblog.bingoai.tk%2fposts%2fparallel_crossentropy%2f&t=About%20Cross%20Entropy">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2020  Bingo.H 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/posts">Posts</a></li>
         
        <li><a href="/tags">Tags</a></li>
         
        <li><a href="/about">About</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/js/main.js"></script>


  


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

</html>
